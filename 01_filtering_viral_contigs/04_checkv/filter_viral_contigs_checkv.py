from Bio import SeqIO
import os
import pandas as pd

def generateFilterlist():
   
    #Step 1
    df = pd.read_csv('quality_summary.tsv',sep='\t')
    df1 = df[(df['contig_length'] >= 3000) & (df['viral_genes'] > 0)]
    print(len(df1))
    #Step 2
    df = pd.read_csv('quality_summary.tsv',sep='\t')
    df2 = df[(df['contig_length'] > 5000) & (df['viral_genes'] == 0) & (df['host_genes'] == 0)]
    print(len(df2))
    #Step 3
    df = pd.read_csv('quality_summary.tsv',sep='\t')
    df3 = df[(df['contig_length'] > 10000) & (df['viral_genes'] == 0) & (df['host_genes'] == 1)]
    print(len(df3))
    #Combine dataframes
    frames = [df1, df2, df3]
    df = pd.concat(frames)

    #Step 4
    df_result = df.drop(df[(df['viral_genes'] * 3 < df['host_genes']) & (df['provirus'] == 'No')].index)
    #print(len(df_result))
    #df_result = df_result[df_result['contig_length'] < 3000].dropna()
    filter = df_result['contig_id']
    #df_result.to_csv(f'MP{s}_filter1_quality_sum.txt', index=False)
    filter.to_csv(f'MP{s}_filter1_list.txt',header=False, index=False)

def filter(fasta_file,headers_file, output_file):

    # Read headers to filter
    with open(headers_file, 'r') as contigs:
        headers_to_keep = {line.strip() for line in contigs}

    # Debugging: Print number of unique headers read
    print(f"Number of unique headers read: {len(headers_to_keep)}")

    # Filter and write sequences
    with open(output_file, 'w') as filtered:
        for record in SeqIO.parse(fasta_file, "fasta"):
            # Extract the first part of the identifier and remove '_1' if present
            if record.id[3:5] == '_1':
                identifier = record.id.split('_1')
                identifier = identifier[0] + '_1' + identifier[1]
                #print(identifier)
            else:
                identifier = record.id.split('_1')[0]
            #identifier = record.id.rstrip('_1 ')
            #print(identifier)
            if identifier in headers_to_keep:
                filtered.write(f">{identifier}\n{record.seq}\n")
            #else:
                # Debugging: Print IDs that are not found
                #print(f"ID not found: {identifier}")
    filtered.close()

    # Check if all headers were used
    used_headers = set()
    with open(output_file, 'r') as check:
        for line in check:
            if line.startswith('>'):
                used_headers.add(line[1:].strip().split()[0])

    # Debugging: Print headers not used
    unused_headers = headers_to_keep - used_headers
    print(f"{len(unused_headers)} Headers not used: {unused_headers}")
    check.close()

def getLength():
    file_open = f'MP{s}_filtered_checkv.fa'
    file_out = open(f'MP{s}_filtered_contig_length.txt','w') 

    for rec in SeqIO.parse(file_open, 'fasta'):
        name = rec.id
        seq = rec.seq
        seqLen = len(seq)
        file_out.write(name + '\t' + str(seqLen) + '\n')

    file_out.close()

dir = os.getcwd()
sample=range(1,6)

for s in sample:

# Parse the input FASTA file
    os.chdir(f'IT{s}_filt_095')

    #Step1 = FGenerate the filter list based on checkV results
    generateFilterlist()

    #Step2 = Filter the contigs based on the MP_filter1_list.txt file generated by checv_filter.py
    filter('combined.fna', f'IT{s}_filter1_list.txt', f'IT{s}_filtered_checkv.fa')

    #Step3 = CheckV displays the contig length before the trimming so it is expected to stil have contigs < 3000
    #Since this contigs passed the quality filters applied before we will maintain them
    #We now check the contig length of the filtered contigs
    getLength()

    #Step 4 = However we still have to remove contigs with less than 1000 bp which will not be annotated by DRAMv 
    c_len = pd.read_csv(f'IT{s}_filtered_contig_length.txt', sep='\t', names=['contig','length'])
    print(len(c_len))
    more_than_3000 = c_len[c_len['length'] >= 3000]
    more_than_3000 = more_than_3000['contig']


    more_than_3000.to_csv('more_than_3000.txt',header=False,index=False)   
    filter(f'IT{s}_filtered_checkv.fa','more_than_3000.txt',f'IT{s}_final_filtered_checkv.fa')


    os.remove(f'IT{s}_filtered_contig_length.txt')
    os.remove(f'IT{s}_filtered_checkv.fa')
    os.remove('more_than_3000.txt')
    os.remove(f'IT{s}_filter1_list.txt')
    
    os.chdir(f'..')
